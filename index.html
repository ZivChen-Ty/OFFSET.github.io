<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="OFFSET: Segmentation-based Focus Shift Revision for Composed Image Retrieval">
  <meta property="og:title" content="OFFSET: Segmentation-based Focus Shift Revision for Composed Image Retrieval" />
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG" />
  <meta property="og:url" content="URL OF THE WEBSITE" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <meta name="twitter:title" content="OFFSET: Segmentation-based Focus Shift Revision for Composed Image Retrieval">
  <meta name="twitter:description"
    content="OFFSET: Segmentation-based Focus Shift Revision for Composed Image Retrieval">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="OFFSET: Segmentation-based Focus Shift Revision for Composed Image Retrieval">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="OFFSET: Segmentation-based Focus Shift Revision for Composed Image Retrieval">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>OFFSET: Segmentation-based Focus Shift Revision for Composed Image Retrieval</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">

        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            More Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://sdu-l.github.io/ENCODER.github.io/">
              Encoder (AAAI'25)
            </a>
            <a class="navbar-item" href="https://zhihfu.github.io/PAIR.github.io/">
              PAIR (ICASSP'25)
            </a>
            <a class="navbar-item" href="https://windlikeo.github.io/MEDIAN.github.io/">
              MEDIAN (ICASSP'25)
            </a>
            <a class="navbar-item" href="https://zivchen-ty.github.io/ARRANGE.github.io/">
              ARRANGE
            </a>
          </div>
        </div>
      </div>
    </div>
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">[ACM MM'25] OFFSET: Segmentation-based Focus Shift Revision for
              Composed Image Retrieval</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <!--               <sup>*</sup> -->
              <!-- <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Zhiwei Chen<sup>1</sup></a>,</span> -->
              <span class="author-block" style="font-weight: 1000;">
                <a href="https://zivchen-ty.github.io" target="_blank" class="author-link">Zhiwei
                  Chen<sup>1</sup></a>,
              </span>
              <span class="author-block" style="font-weight: 1000;">
                <a href="https://faculty.sdu.edu.cn/huyupeng1/zh_CN/index.htm" target="_blank"
                  class="author-link">Yupeng Hu<sup>1*</sup></a>,
              </span>
              <span class="author-block" style="font-weight: 1000;">
                <a href="https://lee-zixu.github.io" target="_blank" class="author-link">Zixu Li<sup>1</sup></a>,
              </span>
              <span class="author-block" style="font-weight: 1000;">
                <a href="https://zhihfu.github.io" target="_blank" class="author-link">Zhiheng Fu<sup>1</sup></a>,
              </span>
              <span class="author-block" style="font-weight: 1000;">
                <a href="https://xuemengsong.github.io" target="_blank" class="author-link">Xuemeng
                  Song<sup>2</sup></a>,
              </span>
              <span class="author-block" style="font-weight: 1000;">
                <a href="https://liqiangnie.github.io/index.html" target="_blank" class="author-link">Liqiang
                  Nie<sup>3</sup></a>,
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>School of Software, Shandong University,<br><sup>2</sup>Department of Data Science, City
                University of Hong Kong,<br><sup>3</sup>School of
                Computer Science and Technology, Harbin Institute of Technology (Shenzhen)
              </span>
              <span class="eql-cntrb"><small><br><sup>*</sup>Corresponding author.</small></span>

            </div>

            <div class="column has-text-centered">
              <div class="publication-links">

                <span class="link-block">
                  <a href="" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper Coming Soon</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-google-drive"></i>
                    </span>
                    <span>Code Coming Soon</span>
                  </a>
                </span>



              </div>
            </div>


          </div>
        </div>
      </div>
    </div>
    </div>
    </div>
  </section>


  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <div class="item">
              <div class="columns is-centered has-text-centered">
                <div class="column is-fifths-fifths">
                  <!-- Your image here -->
                  <img src="static/images/Abstract.png" alt="MY ALT TEXT" />
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->

  <!-- <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Composed Image Retrieval (CIR) represents a novel retrieval paradigm that is capable of expressing users‚Äô
              intricate
              retrieval requirements flexibly. It enables the user to give a multimodal query,
              comprising a reference image and a modification text, and subsequently retrieve the target image.
              Notwithstanding the
              considerable
              advances made by prevailing methodologies, CIR remains in its
              nascent stages due to two limitations: 1) inhomogeneity between
              dominant and noisy portions in visual data is ignored, leading
              to query feature degradation, and 2) the priority of textual data
              in the image modification process is overlooked, which leads to
              a visual focus bias. To address these two limitations, this work
              presents a focus mapping-based feature extractor, which consists
              of two modules: dominant portion segmentation and dual focus
              mapping. It is designed to identify significant dominant portions in
              images and guide the extraction of visual and textual data features,
              thereby reducing the impact of noise interference. Subsequently,
              we propose a textually guided focus revision module, which can
              utilize the modification requirements implied in the text to perform adaptive focus revision on the
              reference image,
              thereby enhancing the perception of the modification focus on the composed
              features. The aforementioned modules collectively constitute the
              segmentatiOn-based Focus shiFt reviSion nETwork (OFFSET), and
              comprehensive experiments on four benchmark datasets substantiate the superiority of our proposed method.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section> -->

  <section class="hero is-small">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <div class="column is-three-fifths">
          <h2 class="title is-3">Inhomogeneity and Text-Priority in Composed Image Retrieval</h2>
          <div class="item">
            <div class="columns is-centered has-text-centered">
              <div class="column is-four-fifths">
                <!-- Your image here -->
                <img src="static/images/Intro.png" alt="MY ALT TEXT" />
                <h2 class="subtitle has-text-centered has-text-justified is-size-6">
                  (a) gives an example of the CIR task. (b) demonstrates the phenomenon of inhomogeneity in visual
                  samples,
                  where images frequently comprise dominant and noisy regions. (c) illustrates the advantages of
                  applying text-priority
                  during multimodal feature composition. The image caption
                  treats ‚Äútrees‚Äù as background noise information, which is inconsistent with the focus on modification
                  text and may
                  result
                  in inaccurate composition results. However, when modification text is the primary objective, ‚Äútrees‚Äù
                  can be
                  re-identified
                  as the dominant region, thereby facilitating the construction
                  of more accurate composed features.
                </h2>
              </div>
            </div>
          </div>
          <br>
        </div>
      </div>
    </div>
  </section>

  <!-- Image carousel -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container  has-text-centered">
        <h2 class="title is-3">Framework: segmentatiOn-based Focus shiFt reviSion nETwork (OFFSET)</h2>
        <!-- <div id="results-carousel" class="carousel results-carousel"> -->
        <div class="item">
          <!-- Your image here -->
          <img src="static/images/Framework.png" alt="MY ALT TEXT" />
          <h2 class="subtitle has-text-centered">
            The proposed OFFSET consists of three key modules: (a) Dominant Portion Segmentation, (b) Dual Focus
            Mapping,
            and (c) Textually Guided Focus Revision, where (a) and (b) collectively form the feature extractor.
          </h2>
        </div>
        <hr>
        <!-- </div> -->
      </div>
    </div>
  </section>
  <!-- End image carousel -->


  <section class="hero is-small">
    <div class="hero-body">
      <div class="container has-text-centered">
        <h2 class="title is-3">Experiment</h2>
        <!-- <div id="results-carousel" class="carousel results-carousel"> -->
        <div class="item">
          <!-- Your image here -->
          <img src="static/images/FIQ.png" alt="MY ALT TEXT" />
          <h2 class="subtitle has-text-centered">
            Performance comparison on FashionIQ relative to R@K(%). The overall best results are in bold, while the
            best results
            over baselines are underlined.
          </h2>
        </div>
        <br>
        <div class="item">
          <!-- Your image here -->
          <img src="static/images/CIRR.png" alt="MY ALT TEXT" />
          <h2 class="subtitle has-text-centered">
            Performance comparison on CIRR with respect to R@K(%) and Rsubsset@K(%). The overall best results are
            in bold,
            while
            the best results over baselines are underlined.
          </h2>
        </div>
        <br>
        <div class="item">
          <!-- Your image here -->
          <img src="static/images/Shoes.png" alt="MY ALT TEXT" />
          <h2 class="subtitle has-text-centered">
            Performance comparison on Shoes with respect to
            R@K(%). The overall best results are in bold, while the best
            results over baselines are underlined.
          </h2>
        </div>
        <br>
        <div class="columns is-centered has-text-centered">
          <div class="column is-three-fifths">
            <div class="item">
              <!-- Your image here -->
              <img src="static/images/ablation.png" alt="MY ALT TEXT" />
              <h2 class="subtitle has-text-centered">
                Ablation Studies of OFFSET with various settings on
                FashionIQ, Shoes, and CIRR. Œî represents the performance
                degradation of the compared derivatives and is marked with
                the green background. The yellow background denotes the
                baseline performance utilized for per column.
              </h2>
            </div>
          </div>
        </div>
        <br>
        <div class="columns is-centered has-text-centered">
          <div class="column is-three-fifths">
            <div class="item">
              <!-- Your image here -->
              <img src="static/images/Sensitivity.png" alt="MY ALT TEXT" />
              <h2 class="subtitle has-text-centered">
                Sensitivity to Focus Channel Number ùëÉ and the
                hyper-parameter ùúá on (a) FashionIQ, (b) Shoes, and (c) CIRR.
              </h2>
            </div>
          </div>
        </div>
        <br>
        <div class="columns is-centered has-text-centered">
          <div class="column is-10">
            <img src="static/images/Case.png" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              Case study on (a) FashionIQ and (b) CIRR.
            </h2>
          </div>
          <!-- </div> -->
        </div>
      </div>
  </section>


  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        @inproceedings{offset,
        title={OFFSET: Segmentation-based Focus Shift Revision for Composed Image Retrieval},
        author={Chen, Zhiwei and Hu, Yupeng and Li, Zixu and Fu, Zhiheng and Song, Xuemeng and Nie, Liqiang},
        booktitle={Proceedings of the 33th ACM International Conference on Multimedia},
        year={2025}
        }
      </code></pre>
    </div>
  </section>
  <!--End BibTex citation -->
  <!-- volume={x},
number={x},
pages={x--x}, -->

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-1">
          <a href="https://clustrmaps.com/site/1c6zr" title="ClustrMaps"><img
              src="//www.clustrmaps.com/map_v2.png?d=IFwQuFU7k0TOrd4qyYWCoIEZINJJh_zVNQMJ26kvvGU&cl=ffffff" /></a>
        </div>
        <div class="column is-8">
          <div class="content">
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Academic Project Page Template</a> which was adopted from the¬†<a
                href="https://nerfies.github.io" target="_blank">Nerfies</a>¬†project page.
              You are free to borrow the source code of this website, we just ask that you link back to this page in the
              footer. <br> This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>

          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

  <!-- End of Statcounter Code -->

</body>

</html>
